Text Summarization Survey
===
Introduction
---
随着近几年文本信息的爆发式增长，人们每天能接触到海量的文本信息，如新闻、博客、聊天、报告、论文、微博等。从大量文本信息中提取重要核心的内容，成为了一个迫切的需求，而自动文本摘要（*automatic text summarization*）则提供了一个高效的解决方案。

根据Radef的定义，摘要是“一段从一份或多份文本中提取出来的文字，它包含了原文本中的重要信息，其长度不超过或远少于原文本的一半”。自动文本摘要通过**非人工**的自动方法，输出简洁、流畅、保留关键信息的摘要。

自动文本摘要有非常多的应用场景，如自动报告生成、新闻标题生成、搜索结果预览等。此外，自动文本摘要也可以为下游任务提供支持。

尽管对自动文本摘要有庞大的需求，这个领域的发展比较缓慢。对计算机而言，生成摘要是一件很有挑战性的任务。从一份或多份文本输出一份合格摘要，要求计算机在阅读原文本后理解其内容，并根据轻重缓急对内容进行取舍，对内容裁剪和拼接，最后生成流畅的短文本。因此，自动文本摘要是自然语言处理/理解的重要分支之一，是近几年来的重要研究方向。

自动文本摘要通常可分为两种，分别是提取式（extractive）和摘要式（abstractive）。抽取式摘要判断原文本中重要的句子，**抽取**这些句子成为一篇摘要。而摘要式方法则应用先进的自然语言处理的算法，通过转述、同义替换、句子缩写等技术，**生成**更凝练简洁的摘要。比起抽取式，摘要式更接近人进行摘要的过程。历史上，抽取式的效果通常优于摘要式。伴随深度神经网络的兴起和研究，基于神经网络的摘要式文本摘要得到快速进步和发展，并取得了不错的成绩。

Extractive summarization
---
TODO

Abstractive summarization
---
TODO

Evaluation
---
评价一篇摘要的质量是一件比较困难的任务。

对于一篇摘要而言，很难说有标准答案。不同于很多拥有客观评判标准的任务，摘要的评判一定程度上依赖主观判断。即使在摘要任务中，有关于语法正确性、语言流畅性、关键信息完整度等标准，摘要的评价还是如同”一千个人眼里有一千个哈姆雷特“一样，每个人对摘要的优劣都有自己的准绳。目前，评估摘要质量主要有两种方法：人工评价方法和自动评价方法。

#### 人工评价方法

自上世纪九十年代末开始，一些会议或组织开始致力于制定摘要评价的标准，他们也会参与评价一些摘要语料集。比较著名的会议和组织包括SUMMAC，DUC（Document Understanding Conference），TAC（Text Analysis Conference）。

TODO

#### 指标
ROUGE

Reference
---
* [Text Summarization Techniques: A Brief Survey](https://arxiv.org/abs/1707.02268)